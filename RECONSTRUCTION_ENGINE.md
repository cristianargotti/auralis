# AURALIS ‚Äî Track-Agnostic Reconstruction Engine Architecture

> **Misi√≥n:** Subir CUALQUIER track ‚Üí AURALIS lo deconstruye, identifica cada elemento, y lo reconstruye pieza por pieza a la misma calidad. 100% agn√≥stico. Cero hardcoded.

## Principio Fundamental

```
Upload ANY track ‚Üí üëÇ EAR deconstruye ‚Üí üß† BRAIN analiza ‚Üí
üìê GRID compone ‚Üí üéπ HANDS sintetiza ‚Üí üéöÔ∏è CONSOLE mezcla/masteriza ‚Üí
üîç QC compara A/B ‚Üí ‚ôªÔ∏è Itera hasta match
```

---

## Capa 1: üëÇ EAR ‚Äî Deconstrucci√≥n Inteligente

**Objetivo:** Descomponer cualquier track en sus elementos constitutivos + extraer ADN musical completo.

### 1.1 Separaci√≥n de Stems

| Tecnolog√≠a | SDR avg | Params | Estado |
|---|---|---|---|
| **Mel-RoFormer** | 9.96 dB | ~50M | ‚úÖ Open source HuggingFace |
| **BS-RoFormer** | 9.80 dB | 72M√ó4 | ‚úÖ Open source |
| HTDemucs v4 | 7.68 dB | ‚Äî | ‚úÖ Ya implementado |
| Moises-Light | 9.96 dB | **5M** | ‚úÖ M√°s eficiente (13√ó menos params) |

> [!IMPORTANT]
> **Decisi√≥n:** Usar **Mel-RoFormer** como separador primario (mejor calidad). Mantener HTDemucs como fallback.
> Configurar N stems: vocals, drums, bass, other, piano, guitar (6-stem mode).

### 1.2 Extracci√≥n MIDI

| Herramienta | Capacidad |
|---|---|
| **Basic-Pitch** (Spotify) | Polif√≥nico, multi-instrumento, pitch bend, r√°pido |
| **MIDI-VALLE** | Expresivo (din√°mica, pedal) ‚Äî piano especializado |
| musicpy | Teor√≠a musical, an√°lisis de progresiones |

**Pipeline:** Cada stem separado ‚Üí Basic-Pitch ‚Üí MIDI + detecci√≥n de tonalidad/escala autom√°tica

### 1.3 Profiling Espectral (ya existe en `profiler.py`)

- RMS por secci√≥n (detectado autom√°ticamente)
- Relaci√≥n S/M (stereo width)
- An√°lisis de envolvente (ADSR por elemento)
- Detecci√≥n de efectos (reverb time, delay, sidechain ratio, filter cutoff)
- Detecci√≥n de BPM + time signature

---

## Capa 2: üéπ HANDS ‚Äî S√≠ntesis Inteligente

**Objetivo:** Re-sintetizar cada elemento identificado usando el timbre m√°s aproximado posible.

### 2.1 Motor de S√≠ntesis Principal

| Herramienta | Uso |
|---|---|
| **DawDreamer** | VST host Python ‚Äî carga Surge XT, Vital, cualquier VST |
| **Faust DSP** | DSP custom integrado en DawDreamer |
| **JAX + Flax** | Optimizaci√≥n de par√°metros de s√≠ntesis ML-driven |

### 2.2 Clonaci√≥n de Timbre

| Tecnolog√≠a | Capacidad | Estado |
|---|---|---|
| **TokenSynth** | Zero-shot instrument cloning via codec LM | ‚úÖ Feb 2025 |
| **RAVE** | Real-time timbre transfer, disponible como VST | ‚úÖ Open source |
| **DDSP** (Google) | Differentiable DSP, pitch/loudness independientes | ‚úÖ Open source |

**Pipeline por stem:**
```
Stem original ‚Üí TokenSynth (identifica timbre)
                ‚Üí Busca preset m√°s cercano en banco de VSTs
                ‚Üí DawDreamer renderiza MIDI con ese preset
                ‚Üí RAVE ajusta timbre fino si necesario
```

### 2.3 Banco de Presets (Track-Agnostic)

En lugar de presets hardcoded, el sistema:
1. Separa stem ‚Üí analiza espectro/ADSR/harmonics
2. Busca en **banco gen√©rico** de presets VST (Surge XT, Vital)
3. Si no hay match suficiente ‚Üí TokenSynth genera timbre zero-shot
4. DawDreamer + JAX optimizan par√°metros del VST para acercarse al original

---

## Capa 3: üéöÔ∏è CONSOLE ‚Äî Mezcla y Master

**Objetivo:** Mezclar stems reconstruidos y masterizar por referencia al original.

### 3.1 Cadena de Efectos

| Herramienta | Uso |
|---|---|
| **Pedalboard** (Spotify) | EQ, comp, reverb, delay, chorus, limiter |
| Sidechain custom | Pump autom√°tico detectado del original |
| Stereo width matcher | Replica S/M ratio por secci√≥n |

### 3.2 Mastering por Referencia

| Herramienta | Capacidad |
|---|---|
| **matchering** | Match autom√°tico de RMS, EQ curve, peak, stereo width |
| **Pedalboard** chain | Multi-band comp, limiter, clipping stagex|

**Pipeline:**
```
Stems reconstruidos ‚Üí Mix con niveles detectados por EAR
‚Üí matchering(mix, original) ‚Üí Master autom√°tico
‚Üí LUFS/RMS target del original
```

---

## Capa 4: üìê GRID ‚Äî Composici√≥n y Arreglo

**Objetivo:** Generar el arreglo completo bar-por-bar basado en el an√°lisis del EAR.

### 4.1 Herramientas

| Herramienta | Uso |
|---|---|
| **mido** | Generaci√≥n/edici√≥n MIDI program√°tica |
| **musicpy** | Teor√≠a musical (escalas, acordes, progresiones) |
| **pretty_midi** | An√°lisis MIDI avanzado |

### 4.2 Detecci√≥n Autom√°tica de Estructura

El GRID no necesita secciones hardcoded. Detecta autom√°ticamente:
1. **Secciones** ‚Äî por cambios de energ√≠a RMS (cliff/jump detection)
2. **Repeticiones** ‚Äî pattern matching en MIDI
3. **Progresi√≥n arm√≥nica** ‚Äî detecci√≥n de acordes por beat
4. **Arreglo** ‚Äî qu√© elementos suenan en cada bar

---

## Capa 5: üß† BRAIN ‚Äî Orquestador LLM

**Objetivo:** Coordinar decisiones de producci√≥n que requieren "intuici√≥n musical".

### 5.1 Funci√≥n

El BRAIN recibe el an√°lisis completo del EAR y toma decisiones:
- **Sound design:** ¬øQu√© tipo de bajo es? ¬øSub, reese, acid?
- **Arreglo:** ¬øD√≥nde poner risers, fills, transiciones?
- **Mixing:** ¬øC√≥mo equilibrar niveles relativos?
- **Correcci√≥n:** Tras QC, ¬øqu√© ajustar?

### 5.2 Stack

| Componente | Tecnolog√≠a |
|---|---|
| LLM | GPT-4o / Claude via API |
| Contexto | An√°lisis EAR completo (JSON) |
| Output | Decisiones estructuradas ‚Üí GRID / HANDS / CONSOLE |

---

## Capa 6: üîç QC ‚Äî Quality Control

**Objetivo:** Comparaci√≥n objetiva A/B entre original y reconstrucci√≥n.

### 6.1 Scoring de 12 Dimensiones

| Dimensi√≥n | M√©todo |
|---|---|
| Spectral similarity | Correlaci√≥n de espectrogramas Mel |
| RMS match per section | dB difference por secci√≥n detectada |
| Stereo width match | S/M ratio comparison |
| Bass pattern match | MIDI note comparison |
| Kick pattern match | Onset detection correlation |
| Harmonic progression | Chord sequence comparison |
| Energy curve | RMS curve correlation (‚â•0.90 target) |
| Reverb match | RT60 estimation comparison |
| Dynamic range | Crest factor comparison |
| BPM accuracy | Phase correlation |
| Arrangement match | Section boundary alignment |
| Timbre similarity | MERT embeddings cosine similarity |

### 6.2 MERT para Timbre

**MERT** (Music Extractor for Retrieval and Tagging): modelo pre-entrenado que genera embeddings de audio para comparaci√≥n de timbre. Cosine similarity entre embeddings del original vs reconstrucci√≥n ‚Üí score de 0-100.

---

## Infraestructura GPU

| Instancia | Uso | Costo |
|---|---|---|
| **t3.small** (always on) | API + UI + job queue | $15/mo |
| **g5.xlarge** (on-demand) | Mel-RoFormer, TokenSynth, RAVE, mastering | ~$1/hr |

Auto-start GPU al subir track ‚Üí procesar ‚Üí auto-stop tras 10 min idle.

---

## Pipeline Completo (Track-Agnostic)

```mermaid
graph TD
    A[Upload ANY track] --> B[üëÇ EAR]
    B --> B1[Mel-RoFormer: 6 stems]
    B --> B2[Basic-Pitch: MIDI por stem]
    B --> B3[Profiler: BPM, key, sections, FX, energy]
    
    B1 --> C[üß† BRAIN]
    B2 --> C
    B3 --> C
    
    C --> C1[Sound Design Decisions]
    C --> C2[Arrangement Plan]
    C --> C3[Mixing Strategy]
    
    C1 --> D[üéπ HANDS]
    C2 --> E[üìê GRID]
    C3 --> F[üéöÔ∏è CONSOLE]
    
    E --> E1[MIDI patterns bar-by-bar]
    E1 --> D
    
    D --> D1[TokenSynth: timbre match]
    D --> D2[DawDreamer: VST render]
    D --> D3[RAVE: timbre fine-tune]
    D2 --> F
    
    F --> F1[Pedalboard: FX chain]
    F --> F2[matchering: master by ref]
    F2 --> G[üîç QC]
    
    G --> G1[12-dimension scoring]
    G --> G2[MERT timbre similarity]
    G1 --> H{Score ‚â• 90%?}
    
    H -->|Yes| I[‚úÖ Reconstruction Complete]
    H -->|No| C
```

---

## Verificaci√≥n

1. Subir Million Pieces en la UI ‚Üí verificar pipeline completo
2. Subir track totalmente diferente (ej: techno, ambient) ‚Üí mismo resultado
3. Score QC ‚â• 85% en 12 dimensiones
4. A/B comparison visual en la UI

## Orden de Ejecuci√≥n

**Fase 1:** Integrar Mel-RoFormer + Basic-Pitch en EAR (reemplazar HTDemucs como primario)
**Fase 2:** Detecci√≥n autom√°tica de secciones/estructura (sin hardcoding)
**Fase 3:** TokenSynth + DawDreamer pipeline de s√≠ntesis
**Fase 4:** matchering integration en CONSOLE
**Fase 5:** QC scoring 12 dimensiones + MERT
**Fase 6:** BRAIN orchestration loop (iterar hasta score ‚â• 90%)
**Fase 7:** UI: upload ‚Üí live pipeline ‚Üí A/B comparison
